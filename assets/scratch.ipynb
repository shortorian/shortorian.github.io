{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def make_bidirectional_map_one_to_many(df):\n",
    "\n",
    "    input_columns = list(df.columns)\n",
    "    df.columns = [0, 1]\n",
    "\n",
    "    # Remove identities and duplicate rows\n",
    "    df = df.loc[df[0] != df[1], :].drop_duplicates()\n",
    "\n",
    "    # Check if the input dataframe is already a one-to-many map\n",
    "    if not df[1].duplicated().any() and not df[1].isin(df[0]).any():\n",
    "        df.columns = input_columns\n",
    "        return df\n",
    "\n",
    "    # Stack the values so we can find duplicate values regardless of the\n",
    "    # column\n",
    "    dummy = df.stack()\n",
    "    dummy = dummy.loc[dummy.duplicated(keep=False)]\n",
    "\n",
    "    ##############################################################\n",
    "    # Locate two different types of duplicate values in the second\n",
    "    # column\n",
    "    ##############################################################\n",
    "\n",
    "    # Get first instance in the second column of values duplicated\n",
    "    # anywhere in the dataframe. \"dummy\" refers to duplicate values in\n",
    "    # the stacked dataframe\n",
    "    first_instance_of_any_dplct_in_c1 = (\n",
    "        dummy.loc[(slice(None), 1)].drop_duplicates()\n",
    "    )\n",
    "\n",
    "    # Get values from the second column which are duplicated anywhere\n",
    "    # in the dataframe but which occurred first in the second column.\n",
    "    # \"dummy\" refers to duplicate values in the stacked dataframe\n",
    "    frst_instnc_of_dplct_found_in_c1_frst = dummy.drop_duplicates()\n",
    "    if 1 in frst_instnc_of_dplct_found_in_c1_frst.index.get_level_values(1):\n",
    "        frst_instnc_of_dplct_found_in_c1_frst = (\n",
    "            frst_instnc_of_dplct_found_in_c1_frst.loc[(slice(None), 1)]\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        frst_instnc_of_dplct_found_in_c1_frst = pd.Series([], dtype=int)\n",
    "\n",
    "    # If values duplicated anywhere in the dataframe exist in the\n",
    "    # second column, map the duplicates to the first-column\n",
    "    # partner of the first instance of the value in the second column\n",
    "    if df[1].duplicated().any():\n",
    "\n",
    "        ##############################################################\n",
    "        # Make maps between the different kinds of first second-column\n",
    "        # instances and their first-column partners\n",
    "        ##############################################################\n",
    "\n",
    "        # Map from the first instance in the second column of values\n",
    "        # duplicated anywhere in the dataframe to their first-column\n",
    "        # partners.\n",
    "        # \"dummy\" refers to duplicate values in the stacked dataframe\n",
    "        dummy = df.loc[first_instance_of_any_dplct_in_c1.index]\n",
    "        map_to_c0_from_frst_instnc_of_any_dplct_in_c1 = pd.Series(\n",
    "            dummy[0].array,\n",
    "            index=dummy[1].array\n",
    "        )\n",
    "\n",
    "        # Map from duplicate values that occurred first in the second\n",
    "        # column to the first-column partners of their first instance\n",
    "        map_to_c0_from_frst_instnc_of_dplct_found_in_c1_frst = df.loc[\n",
    "            frst_instnc_of_dplct_found_in_c1_frst.index,\n",
    "            :\n",
    "        ]\n",
    "        map_to_c0_from_frst_instnc_of_dplct_found_in_c1_frst = pd.Series(\n",
    "            map_to_c0_from_frst_instnc_of_dplct_found_in_c1_frst[0].array,\n",
    "            index=map_to_c0_from_frst_instnc_of_dplct_found_in_c1_frst[1].array\n",
    "        )\n",
    "\n",
    "        ################\n",
    "        # Apply the maps\n",
    "        ################\n",
    "\n",
    "        # Get rows with values in the first column that appeared\n",
    "        # first in the second column\n",
    "        c0_value_was_found_in_c1_first = df.loc[\n",
    "            df[0].isin(first_instance_of_any_dplct_in_c1),\n",
    "            :\n",
    "        ]\n",
    "\n",
    "        # Map those values to the first-column partners of their first\n",
    "        # instances in the second column\n",
    "        mapped = c0_value_was_found_in_c1_first[0].map(\n",
    "            map_to_c0_from_frst_instnc_of_any_dplct_in_c1\n",
    "        )\n",
    "        df.loc[c0_value_was_found_in_c1_first.index, 0] = mapped.array\n",
    "\n",
    "        # Get all duplicate values in the second column which appeared first\n",
    "        # in the second column\n",
    "        c1_value_was_found_in_c1_first = df.loc[\n",
    "            df[1].isin(frst_instnc_of_dplct_found_in_c1_frst),\n",
    "            :\n",
    "        ]\n",
    "\n",
    "        # Drop the first instances to isolate only the duplicates\n",
    "        c1_value_was_found_in_c1_first = c1_value_was_found_in_c1_first.drop(\n",
    "            frst_instnc_of_dplct_found_in_c1_frst.index\n",
    "        )\n",
    "\n",
    "        # If there are duplicate values in the second column which\n",
    "        # appeared first in the second column, map those values to the\n",
    "        # first-column partners of their first instances and then swap\n",
    "        # values in those rows so the first instance's first-column\n",
    "        # partner is in the first column\n",
    "\n",
    "        if not c1_value_was_found_in_c1_first.empty:\n",
    "            mapped = c1_value_was_found_in_c1_first[1].map(\n",
    "                map_to_c0_from_frst_instnc_of_dplct_found_in_c1_frst\n",
    "            )\n",
    "            df.loc[c1_value_was_found_in_c1_first.index, :] = list(zip(\n",
    "                mapped.array,\n",
    "                df.loc[c1_value_was_found_in_c1_first.index, 0]\n",
    "            ))\n",
    "            df.drop_duplicates(inplace=True)\n",
    "        \n",
    "        # Remove any identities or duplicate rows created above\n",
    "        df = df.loc[df[0] != df[1], :].drop_duplicates()\n",
    "\n",
    "    # Rearrange the dataframe so that values which appear in both\n",
    "    # columns appear first in the second column\n",
    "\n",
    "    dummy = df[1].isin(df[0])\n",
    "    df = pd.concat([df.loc[dummy], df.loc[~dummy]])\n",
    "\n",
    "    dummy = df[0].isin(df[1])\n",
    "    df = pd.concat([df.loc[~dummy], df.loc[dummy]])\n",
    "\n",
    "    # In some cases the above algorithm will loop indefinitely if there\n",
    "    # are values that occur in both columns but there are no repeated\n",
    "    # values in the second column. Avoid this finding rows with values\n",
    "    # in the first column that are present in the second column and, if\n",
    "    # any exist, swapping values in the first row found.\n",
    "    dummy = df[0].isin(df[1])\n",
    "\n",
    "    if dummy.any():\n",
    "        to_swap = df.loc[dummy].index[0]\n",
    "        df.loc[to_swap, :] = df.loc[to_swap, [1, 0]].to_numpy()\n",
    "\n",
    "    df.columns = input_columns\n",
    "\n",
    "    # Remap the modified dataframe\n",
    "    return make_bidirectional_map_one_to_many(df)\n",
    "\n",
    "df = pd.DataFrame({'tail': [1, 4, 2, 4, 6, 5, 7, 8], 'head': [2, 1, 3, 3, 8, 4, 6, 7]})\n",
    "make_bidirectional_map_one_to_many(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heads duplicated\n",
      "loop\n",
      "no duplicate heads\n",
      "     0   1\n",
      "5    1   4\n",
      "1    1   1\n",
      "4    6   8\n",
      "6    7   6\n",
      "7    8   7\n",
      "8   10  11\n",
      "9   11  12\n",
      "10  12  10\n",
      "3    5   5\n",
      "0    5   2\n",
      "2    5   3\n",
      "Int64Index([5, 4, 8], dtype='int64')\n",
      "loop\n",
      "heads duplicated\n",
      "loop\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "7   8   7\n",
       "9  11  12\n",
       "5   4   1\n",
       "4   8   6\n",
       "8  11  10\n",
       "0   5   2\n",
       "2   5   3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def recursive_universalizer(df):\n",
    "\n",
    "    input_columns = list(df.columns)\n",
    "    df.columns = [0, 1]\n",
    "\n",
    "    # Remove identities and duplicate rows\n",
    "    df = df.loc[df[0] != df[1], :].drop_duplicates()\n",
    "\n",
    "    # Check if the input dataframe is already a one-to-many map\n",
    "    if not df[1].duplicated().any() and not df[1].isin(df[0]).any():\n",
    "        df.columns = input_columns\n",
    "        return df\n",
    "    \n",
    "    # Rearrange the dataframe so that values which appear in both\n",
    "    # columns appear first in the second column\n",
    "\n",
    "    dummy = df[1].isin(df[0])\n",
    "    df = pd.concat([df.loc[dummy], df.loc[~dummy]])\n",
    "\n",
    "    dummy = df[0].isin(df[1])\n",
    "    df = pd.concat([df.loc[~dummy], df.loc[dummy]])\n",
    "\n",
    "    # Stack the values so we can find duplicate values regardless of the\n",
    "    # column\n",
    "    dummy = df.stack()\n",
    "    dummy = dummy.loc[dummy.duplicated(keep=False)]\n",
    "\n",
    "    # isolate multiply connected nodes at the head of at least one\n",
    "    # edge\n",
    "    possible_leaves = dummy.loc[(slice(None), 1)].drop_duplicates()\n",
    "        \n",
    "    # isolate multiply connected nodes that appear first at the head\n",
    "    # of an edge\n",
    "    possible_roots = dummy.drop_duplicates()\n",
    "    if 1 in possible_roots.index.get_level_values(1):\n",
    "        possible_roots = possible_roots.loc[(slice(None), 1)]\n",
    "    else:\n",
    "        possible_roots = pd.Series([], dtype=int)\n",
    "\n",
    "    # Map from the first instance in the second column of values\n",
    "    # duplicated anywhere in the dataframe to their first-column\n",
    "    # partners.\n",
    "    # \"dummy\" refers to duplicate values in the stacked dataframe\n",
    "    # moves nodes from the head of the first edge pointing to \n",
    "    # multiply connected nodes to the tail of that edge\n",
    "    leaves_to_branches = df.loc[possible_leaves.index]\n",
    "    leaves_to_branches = pd.Series(\n",
    "        leaves_to_branches[0].array,\n",
    "        index=leaves_to_branches[1].array\n",
    "    )\n",
    "\n",
    "    # Get rows with values in the first column that appear at least\n",
    "    # once in the second column\n",
    "    # These are edges whose tails are at multiply connected nodes\n",
    "    # attached to at least one head\n",
    "    possible_leaves = df.loc[df[0].isin(possible_leaves), :]\n",
    "\n",
    "    # Map those values to the first-column partners of their first\n",
    "    # instances in the second column\n",
    "    df.loc[possible_leaves.index, 0] = (\n",
    "        possible_leaves[0].map(leaves_to_branches).array\n",
    "    )\n",
    "\n",
    "    # If there are shared leaves\n",
    "    if df[1].duplicated().any():\n",
    "        print('heads duplicated')\n",
    "\n",
    "        ##############################################################\n",
    "        # Make maps between the different kinds of first second-column\n",
    "        # instances and their first-column partners\n",
    "        ##############################################################\n",
    "\n",
    "        '''# Map from the first instance in the second column of values\n",
    "        # duplicated anywhere in the dataframe to their first-column\n",
    "        # partners.\n",
    "        # \"dummy\" refers to duplicate values in the stacked dataframe\n",
    "        # moves nodes from the head of the first edge pointing to \n",
    "        # multiply connected nodes to the tail of that edge\n",
    "        leaves_to_branches = df.loc[possible_leaves.index]\n",
    "        leaves_to_branches = pd.Series(\n",
    "            leaves_to_branches[0].array,\n",
    "            index=leaves_to_branches[1].array\n",
    "        )'''\n",
    "\n",
    "        # Map from duplicate values that occurred first in the second\n",
    "        # column to the first-column partners of their first instance\n",
    "\n",
    "        branches_to_roots = df.loc[possible_roots.index]\n",
    "        branches_to_roots = pd.Series(\n",
    "            branches_to_roots[0].array,\n",
    "            index=branches_to_roots[1].array\n",
    "        )\n",
    "\n",
    "        ################\n",
    "        # Apply the maps\n",
    "        ################\n",
    "\n",
    "        '''# Get rows with values in the first column that appear at least\n",
    "        # once in the second column\n",
    "        # These are edges whose tails are at multiply connected nodes\n",
    "        # attached to at least one head\n",
    "        possible_leaves = df.loc[df[0].isin(possible_leaves), :]\n",
    "\n",
    "        # Map those values to the first-column partners of their first\n",
    "        # instances in the second column\n",
    "        df.loc[possible_leaves.index, 0] = (\n",
    "            possible_leaves[0].map(leaves_to_branches).array\n",
    "        )'''\n",
    "\n",
    "        # Get all duplicate values in the second column which appeared\n",
    "        # first in the second column and drop the first instances to\n",
    "        # isolate only the duplicates\n",
    "        shared_leaves = df.loc[df[1].isin(possible_roots), :].drop(\n",
    "            possible_roots.index\n",
    "        )\n",
    "\n",
    "        # If there are duplicate values in the second column which\n",
    "        # appeared first in the second column, map those values to the\n",
    "        # first-column partners of their first instances and then swap\n",
    "        # values in those rows so the first instance's first-column\n",
    "        # partner is in the first column\n",
    "\n",
    "        if not shared_leaves.empty:\n",
    "            df.loc[shared_leaves.index, :] = list(zip(\n",
    "                shared_leaves[1].map(branches_to_roots).array,\n",
    "                df.loc[shared_leaves.index, 0]\n",
    "            ))\n",
    "            df.drop_duplicates(inplace=True)\n",
    "        \n",
    "        # Remove any identities or duplicate rows created above\n",
    "        df = df.loc[df[0] != df[1], :].drop_duplicates()\n",
    "\n",
    "    else:\n",
    "        print('no duplicate heads')\n",
    "        print(df)\n",
    "        dummy = df.stack()\n",
    "\n",
    "        first_occurrences = dummy.drop_duplicates()\n",
    "\n",
    "        first_occurrences = first_occurrences.loc[\n",
    "            first_occurrences.index.get_level_values(0).duplicated()\n",
    "        ]\n",
    "        to_swap = first_occurrences.index.get_level_values(0)\n",
    "        print(to_swap)\n",
    "        df.loc[to_swap, :] = df.loc[to_swap, [1, 0]].to_numpy()\n",
    "        #return df\n",
    "\n",
    "    '''# In some cases the above algorithm will loop indefinitely if there\n",
    "    # are values that occur in both columns but there are no repeated\n",
    "    # values in the second column. Avoid this finding rows with values\n",
    "    # in the first column that are present in the second column and, if\n",
    "    # any exist, swapping values in the first row found.\n",
    "    dummy = df[0].isin(df[1])\n",
    "\n",
    "    if dummy.any():\n",
    "        print('kludged!')\n",
    "        to_swap = df.loc[dummy].index[0]\n",
    "        print(df.loc[dummy], '\\n')\n",
    "        df.loc[to_swap, :] = df.loc[to_swap, [1, 0]].to_numpy()\n",
    "\n",
    "    df.columns = input_columns'''\n",
    "\n",
    "    # Remap the modified dataframe\n",
    "    print('loop')\n",
    "    return recursive_universalizer(df)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({0: [1, 4, 2, 4, 6, 5, 7, 8, 10, 11, 12], 1: [2, 1, 3, 3, 8, 4, 6, 7, 11, 12, 10]})\n",
    "#df = pd.DataFrame({0: [1, 2, 3, 4, 5, 6, 7], 1: [4, 1, 2, 3, 7, 5, 6]})\n",
    "#df = pd.DataFrame({0: [5,9,1,3,3,8,6,4,9,1], 1: [8,0,5,1,1,9,8,6,0,0]})\n",
    "''' a  b\n",
    "0  5  8\n",
    "1  9  0\n",
    "2  1  5\n",
    "3  3  1\n",
    "4  3  1\n",
    "5  8  9\n",
    "6  6  8\n",
    "7  4  6\n",
    "8  9  0\n",
    "9  1  0'''\n",
    "recursive_universalizer(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "number_of_runs = 1e3\n",
    "\n",
    "def run_it():\n",
    "    pop_size = 1e1\n",
    "    sample_size = 1e1\n",
    "\n",
    "    t = str(time.time()).split('.')\n",
    "    s1 = int(t[0])\n",
    "    s2 = int(t[1])\n",
    "    pop = pd.Series(pd.RangeIndex(stop=pop_size))\n",
    "    sampled = pd.DataFrame({\n",
    "        'a': pop.sample(int(sample_size), replace=True, random_state=s1).array,\n",
    "        'b': pop.sample(int(sample_size), replace=True, random_state=s2).array\n",
    "    })\n",
    "    print(sampled)\n",
    "\n",
    "    try:\n",
    "        #make_bidirectional_map_one_to_many(sampled)\n",
    "        recursive_universalizer(sampled)\n",
    "\n",
    "    except:\n",
    "        raise RuntimeError\n",
    "\n",
    "for i in range(1, int(number_of_runs) + 1):\n",
    "    time.sleep(.005)\n",
    "    run_it()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "815b2be54127abaf32a64efea7cd3ff17cdf2bced9eda4b4c37568bb3e1c75a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
